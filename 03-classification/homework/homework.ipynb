{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "> Note: sometimes your answer doesn't match one of the options exactly. That's fine. \n",
    "Select the option that's closest to your solution.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this homework, we will use the Car price dataset. Download it from [here](https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv).\n",
    "\n",
    "Or you can do it with `wget`:\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv\n",
    "```\n",
    "\n",
    "We'll keep working with the `MSRP` variable, and we'll transform it to a classification task. \n",
    "\n",
    "### Features\n",
    "\n",
    "For the rest of the homework, you'll need to use only these columns:\n",
    "\n",
    "* `Make`,\n",
    "* `Model`,\n",
    "* `Year`,\n",
    "* `Engine HP`,\n",
    "* `Engine Cylinders`,\n",
    "* `Transmission Type`,\n",
    "* `Vehicle Style`,\n",
    "* `highway MPG`,\n",
    "* `city mpg`\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "* Select only the features from above and transform their names using next line:\n",
    "  ```\n",
    "  data.columns = data.columns.str.replace(' ', '_').str.lower()\n",
    "  ```\n",
    "* Fill in the missing values of the selected features with 0.\n",
    "* Rename `MSRP` variable to `price`.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column `transmission_type`?\n",
    "\n",
    "- `AUTOMATIC`\n",
    "- `MANUAL`\n",
    "- `AUTOMATED_MANUAL`\n",
    "- `DIRECT_DRIVE`\n",
    "\n",
    "\n",
    "### Question 2\n",
    "\n",
    "Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your dataset. \n",
    "In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset.\n",
    "\n",
    "What are the two features that have the biggest correlation in this dataset?\n",
    "\n",
    "- `engine_hp` and `year`\n",
    "- `engine_hp` and `engine_cylinders`\n",
    "- `highway_mpg` and `engine_cylinders`\n",
    "- `highway_mpg` and `city_mpg`\n",
    "\n",
    "\n",
    "### Make `price` binary\n",
    "\n",
    "* Now we need to turn the `price` variable from numeric into a binary format.\n",
    "* Let's create a variable `above_average` which is `1` if the `price` is above its mean value and `0` otherwise.\n",
    "\n",
    "### Split the data\n",
    "\n",
    "* Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "* Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`.\n",
    "* Make sure that the target value (`price`) is not in your dataframe.\n",
    "\n",
    "### Question 3\n",
    "\n",
    "* Calculate the mutual information score between `above_average` and other categorical variables in our dataset. \n",
    "  Use the training set only.\n",
    "* Round the scores to 2 decimals using `round(score, 2)`.\n",
    "\n",
    "Which of these variables has the lowest mutual information score?\n",
    "  \n",
    "- `make`\n",
    "- `model`\n",
    "- `transmission_type`\n",
    "- `vehicle_style`\n",
    "\n",
    "\n",
    "### Question 4\n",
    "\n",
    "* Now let's train a logistic regression.\n",
    "* Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "* Fit the model on the training dataset.\n",
    "    - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "    - `model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)`\n",
    "* Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "What accuracy did you get?\n",
    "\n",
    "- 0.60\n",
    "- 0.72\n",
    "- 0.84\n",
    "- 0.95\n",
    "\n",
    "\n",
    "### Question 5\n",
    "\n",
    "* Let's find the least useful feature using the *feature elimination* technique.\n",
    "* Train a model with all these features (using the same parameters as in Q4).\n",
    "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature. \n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "- `year`\n",
    "- `engine_hp`\n",
    "- `transmission_type`\n",
    "- `city_mpg`\n",
    "\n",
    "> **Note**: the difference doesn't have to be positive\n",
    "\n",
    "\n",
    "### Question 6\n",
    "\n",
    "* For this question, we'll see how to use a linear regression model from Scikit-Learn.\n",
    "* We'll need to use the original column `price`. Apply the logarithmic transformation to this column.\n",
    "* Fit the Ridge regression model on the training data with a solver `'sag'`. Set the seed to `42`.\n",
    "* This model also has a parameter `alpha`. Let's try the following values: `[0, 0.01, 0.1, 1, 10]`.\n",
    "* Round your RMSE scores to 3 decimal digits.\n",
    "\n",
    "Which of these alphas leads to the best RMSE on the validation set?\n",
    "\n",
    "- 0\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "\n",
    "> **Note**: If there are multiple options, select the smallest `alpha`.\n",
    "\n",
    "\n",
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://forms.gle/FFfNjEP4jU4rxnL26\n",
    "* You can submit your solution multiple times. In this case, only the last submission will be used \n",
    "* If your answer doesn't match options exactly, select the closest one\n",
    "\n",
    "\n",
    "## Deadline\n",
    "\n",
    "The deadline for submitting is 2 October (Monday), 23:00 CEST.\n",
    "\n",
    "After that, the form will be closed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['Make',\n",
    "            'Model',\n",
    "            'Year',\n",
    "            'Engine HP',\n",
    "            'Engine Cylinders',\n",
    "            'Transmission Type',\n",
    "            'Vehicle Style',\n",
    "            'highway MPG',\n",
    "            'city mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[FEATURES+['MSRP']]\n",
    "data.columns = data.columns.str.replace(' ', '_').str.lower()\n",
    "data.fillna(0, inplace=True)\n",
    "data.rename(columns={'msrp':'price'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['make', 'model', 'year', 'engine_hp', 'engine_cylinders',\n",
       "       'transmission_type', 'vehicle_style', 'highway_mpg', 'city_mpg',\n",
       "       'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    AUTOMATIC\n",
       "Name: transmission_type, dtype: object"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.transmission_type.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_hp</th>\n",
       "      <th>year</th>\n",
       "      <th>engine_cylinders</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>city_mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>engine_hp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.338714</td>\n",
       "      <td>0.774851</td>\n",
       "      <td>-0.415707</td>\n",
       "      <td>-0.424918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.338714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040708</td>\n",
       "      <td>0.258240</td>\n",
       "      <td>0.198171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine_cylinders</th>\n",
       "      <td>0.774851</td>\n",
       "      <td>-0.040708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.614541</td>\n",
       "      <td>-0.587306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highway_mpg</th>\n",
       "      <td>-0.415707</td>\n",
       "      <td>0.258240</td>\n",
       "      <td>-0.614541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_mpg</th>\n",
       "      <td>-0.424918</td>\n",
       "      <td>0.198171</td>\n",
       "      <td>-0.587306</td>\n",
       "      <td>0.886829</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  engine_hp      year  engine_cylinders  highway_mpg  city_mpg\n",
       "engine_hp          1.000000  0.338714          0.774851    -0.415707 -0.424918\n",
       "year               0.338714  1.000000         -0.040708     0.258240  0.198171\n",
       "engine_cylinders   0.774851 -0.040708          1.000000    -0.614541 -0.587306\n",
       "highway_mpg       -0.415707  0.258240         -0.614541     1.000000  0.886829\n",
       "city_mpg          -0.424918  0.198171         -0.587306     0.886829  1.000000"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMERICAL_FEATURES = [ 'engine_hp', 'year', 'engine_cylinders', 'highway_mpg', 'city_mpg']\n",
    "data[NUMERICAL_FEATURES].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 features with biggest correlation are: `highway_mpg` and `city_mpg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make `price` binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['above_average'] = (data.price > data.price.mean())*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('price', axis=1)\n",
    "\n",
    "data_full_train, data_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "data_train, data_val = train_test_split(data_full_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make                  object\n",
       "model                 object\n",
       "year                   int64\n",
       "engine_hp            float64\n",
       "engine_cylinders     float64\n",
       "transmission_type     object\n",
       "vehicle_style         object\n",
       "highway_mpg            int64\n",
       "city_mpg               int64\n",
       "above_average          int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: 0.24\n",
      "model: 0.46\n",
      "transmission_type: 0.02\n",
      "vehicle_style: 0.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "for c in data_full_train.select_dtypes('object').columns:\n",
    "  score = mutual_info_score(data_full_train.above_average, data_full_train[c])\n",
    "  print(f'{c}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "dicts_train = data_train.drop('above_average', axis=1).to_dict(orient='records')\n",
    "\n",
    "dv.fit(dicts_train)\n",
    "\n",
    "X_train = dv.transform(dicts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, max_iter=1000, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_q4 = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "y_train = data_train.above_average.values\n",
    "model_q4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.07033780e-04, 9.97720253e-01, 6.97938861e-05, ...,\n",
       "       1.01043039e-04, 9.91013704e-01, 9.90912809e-01])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts_val = data_val.drop('above_average', axis=1).to_dict(orient='records')\n",
    "\n",
    "X_val = dv.transform(dicts_val)\n",
    "\n",
    "y_pred = model_q4.predict_proba(X_val)[:,1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred>=0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = data_val.above_average.values\n",
    "(y_pred==y_val).mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train.above_average.values\n",
    "data_train.drop('above_average', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = data_val.above_average.values\n",
    "data_val.drop('above_average', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "\n",
    "def train_and_score(model, training_dataset, y_train, validation_dataset, y_true):\n",
    "\n",
    "    dv = DictVectorizer()\n",
    "\n",
    "    dicts_train = training_dataset.to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(dicts_train)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    dicts_val = validation_dataset.to_dict(orient='records')\n",
    "    X_val = dv.transform(dicts_val)\n",
    "\n",
    "    y_pred = model.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_pred>=0.5)*1\n",
    "    score = (y_pred==y_true).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.946286193873269"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_score = train_and_score(model, data_train, y_train, data_val, y_val)\n",
    "total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data_train.columns\n",
    "scores = []\n",
    "for col in columns:\n",
    "    small_train = data_train.drop(col, axis=1)\n",
    "    small_val = data_val.drop(col, axis=1)\n",
    "    score = train_and_score(model, small_train, y_train, small_val, y_val)\n",
    "    scores.append((col, score, abs(total_score-score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('city_mpg', 0.9458665547629039, 0.0004196391103650221),\n",
       " ('engine_cylinders', 0.9471254720939991, 0.0008392782207301552),\n",
       " ('transmission_type', 0.9450272765421738, 0.0012589173310951773),\n",
       " ('year', 0.9479647503147294, 0.0016785564414604215),\n",
       " ('highway_mpg', 0.9441879983214435, 0.0020981955518254436),\n",
       " ('make', 0.9492236676458246, 0.002937473772555599),\n",
       " ('vehicle_style', 0.9425094418799832, 0.003776751993285754),\n",
       " ('engine_hp', 0.9303399076793957, 0.015946286193873282),\n",
       " ('model', 0.9240453210239195, 0.022240872849349502)]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores, key=lambda x:x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_train, data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "data_train, data_val = train_test_split(data_full_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log1p(data_train.price)\n",
    "y_val = np.log1p(data_val.price)\n",
    "\n",
    "data_train.drop('price', axis=1, inplace=True)\n",
    "data_val.drop('price', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "dicts_train = data_train.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(dicts_train)\n",
    "\n",
    "dicts_val = data_val.to_dict(orient='records')\n",
    "X_val = dv.transform(dicts_val)\n",
    "\n",
    "results = []\n",
    "for a in [0, 0.01, 0.1, 1, 10]:\n",
    "    ridge_model = Ridge(solver='sag', random_state=42, alpha=a)\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = ridge_model.predict(X_val)\n",
    "    rmse =  mean_squared_error(y_pred, y_val, squared=False)\n",
    "\n",
    "    results.append({'alpha': a, 'rmse': round(rmse, 3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'alpha': 0, 'rmse': 0.248},\n",
       " {'alpha': 0.01, 'rmse': 0.248},\n",
       " {'alpha': 0.1, 'rmse': 0.248},\n",
       " {'alpha': 1, 'rmse': 0.252},\n",
       " {'alpha': 10, 'rmse': 0.33}]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key=lambda x:x['rmse'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
